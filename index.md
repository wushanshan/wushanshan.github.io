---
layout: page
title: Shanshan Wu
---
  <table width="700" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
     <td width="73%" valign="middle">
        <p>
        As of Sept 2019, I got my PhD from the ECE Department at the <a href="http://www.utexas.edu">University of Texas at Austin</a>. I am fortunate to be advised by <a href="http://users.ece.utexas.edu/~sanghavi/">Sujay Sanghavi</a> and <a href="http://users.ece.utexas.edu/~dimakis/">Alex Dimakis</a>. My next stop is Google Research, with a focus on <a href="https://federated.withgoogle.com/">Federated Learning</a>. I got my BS degree in 2011 and MS degree in 2014 from <a href="http://umji.sjtu.edu.cn">Shanghai Jiao Tong University</a>, advised by <a href="https://scholar.google.com/citations?user=oG2PlTsAAAAJ&hl=en">Xudong Wang</a>. 
       </p>
       <p>
       My PhD research focuses on large-scale machine learning, which can be splitted into two parts: the <b>algorithm/theory</b> part and the <b>practice/implementation</b> part. For the algorithm/theory part, I have worked on several different projects, including graphical models, dimensionality reduction, compressed sensing, gradient tree boosting, neural networks, kernel learning, collaborative ranking, and natural language processing. For the practice/implementation part, I have used different platforms/libraries, including Apache Spark, XGBoost, scikit-learn, Tensorflow, PyTorch, and Gurobi. Code of some projects can be found under <a href="https://github.com/wushanshan">my GitHub</a>.
        </p>
       I can be reached at <a href="mailto:shanshan@utexas.edu">shanshan@utexas.edu</a> 
        </td>
        <td width="25%">
        <img src="../images/github_pic.jpg">
        </td>
      </tr>
      </table>

---


## Publications
<p>
<b><a href="https://arxiv.org/abs/1911.07956">
Implicit Regularization and Convergence for Weight Normalization</a></b><br>
Xiaoxia Wu*, Edgar Dobriban*, Tongzheng Ren*, <b>Shanshan Wu*</b>, Yuanzhi Li, Suriya Gunasekar, Rachel Ward, Qiang Liu<br>
Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2020<br>
<i>*Equal contribution</i>
</p>

<p>
<b><a href="https://arxiv.org/abs/1909.01812">
Learning Distributions Generated by One-Layer ReLU Networks</a></b><br>
<a href="https://github.com/wushanshan/densityEstimation">[Code]</a>&nbsp;<a href="https://github.com/wushanshan/densityEstimation/tree/master/poster">[Poster]</a><br>
<b>Shanshan Wu</b>, Alex Dimakis, Sujay Sanghavi<br>
Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2019
</p>

<p>
<b><a href="https://arxiv.org/abs/1810.11905">
Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models</a></b> <br>
<a href="https://github.com/wushanshan/GraphLearn">[Code]</a>&nbsp;<a href="https://github.com/wushanshan/GraphLearn/tree/master/poster">[Poster]</a><br>
<b>Shanshan Wu</b>, Sujay Sanghavi, Alex Dimakis<br>
Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2019 (<b>Spotlight</b>)<br>
Short version in NeurIPS Workshop on Relational Representation Learning, 2018. <a href="../files/GraphicalModel_workshop.pdf">[workshop version]</a>
</p>

<p>
<b><a href="https://arxiv.org/abs/1806.10175">Learning a Compressed Sensing Measurement Matrix via Gradient Unrolling</a></b> <br>
<a href="https://github.com/wushanshan/L1AE">[Code]</a>&nbsp;<a href="../files/ICML_poster_sparseAE.pdf">[Poster]</a> <br>
<b>Shanshan Wu</b>, Alex Dimakis, Sujay Sanghavi, Felix X. Yu, Dan Holtmann-Rice, Dmitry Storcheus, Afshin Rostamizadeh, and Sanjiv Kumar<br>
International Conference on Machine Learning (<b>ICML</b>) 2019.
</p>

<p>
<b><a href="https://arxiv.org/abs/1610.06656">Single Pass PCA of Matrix Products</a></b> <br>
<a href="https://github.com/wushanshan/MatrixProductPCA">[Code]</a>&nbsp;<a href="https://youtu.be/Ir4-eNz6tOw">[Spotlight Video]</a>&nbsp;<a href="../files/OnePassPCAPoster.pdf">[Poster]</a><br>
<b>Shanshan Wu</b>, Srinadh Bhojanapalli, Sujay Sanghavi, and Alex Dimakis<br>
Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2016.
</p>

<p>
<b><a href="http://erikml.com/leveraging-sparsity.pdf">Leveraging Sparsity for Efficient Submodular Data Summarization</a></b> <br>
<a href="https://www.youtube.com/watch?v=9sKLx09bAAE">[Spotlight Video]</a><br>
Erik Lindgren, <b>Shanshan Wu</b>, and Alex Dimakis<br>
Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2016.
</p>

<p>
	<b><a href="../files/nips2015.pdf">Sparse and Greedy: Sparsifying Submodular Facility Location Problems</a></b><br>
	<a href="https://github.com/ErikML/sfl-easylsh">[Code]</a><br>
              Erik Lindgren, <b>Shanshan Wu</b>, and Alex Dimakis<br>
              NeurIPS workshop OPT 2015. <br>
</p>

<p>
	<b><a href="../files/TVT.pdf">Distributed Opportunistic Scheduling with QoS Constraints for Wireless Networks with Hybrid Links</a></b><br>
              Wenguang Mao, Xudong Wang, and <b>Shanshan Wu</b><br>
              IEEE Transactions on Vehicular Technology (<b>TVT</b>), 2015.<br>
              An earlier version appears in Proceedings of the IEEE Globecom, 2013.<br>
</p>

<p>
	<b><a href="../files/MU-MIMO.pdf">Performance Study on a CSMA/CA-Based MAC Protocol for Multi-User MIMO Wireless LANs</a></b><br>
	      <a href="https://github.com/wushanshan/MU-MIMO-WLAN">[Code]</a><br>
              <b>Shanshan Wu</b>, Wenguang Mao, and Xudong Wang<br>
              IEEE Transactions on Wireless Communications (<b>TWC</b>), 2014.<br>
              An earlier version appears in Proceedings of the IEEE Globecom, 2013.<br>
</p>
<p>
	<b><a href="../files/TW-Relay.pdf">Information-theoretic study on routing path selection in two-way relay networks</a></b><br>
              <b>Shanshan Wu</b>, Wenguang Mao, and Xudong Wang<br>
              Proceedings of the IEEE Globecom, 2013. <br>
</p>

---

## Internships
<p>
<b>June 2018 - August 2018</b>
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Software Engineer Intern | Google Research, New York City
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Boosting Random Features	
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;With Petros Mol and Natalia Ponomareva
</p>
<p>
<b>June 2017 - August 2017</b>
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Software Engineer Intern | Google Research, New York City
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Representation Learning for High-Dimensioanl Sparse Data	
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;With Dmitry Storcheus, Felix X. Yu, Dan Holtmann-Rice, Afshin Rostamizadeh, and Sanjiv Kumar
</p>
<p>
<b>Jan 2017 - April 2017</b>
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Applied Scientist Intern | Amazon AI, East Palo Alto
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Joint Learning for Named Entity Recognition and Neural Machine Translation
</p>
<p>
&nbsp;&nbsp;&nbsp;&nbsp;With Hyokun Yun and Anima Anandkumar
</p>

---
## Professional services
<p>
<b>Conference reviewer:</b><br> 
	NeurIPS 2016/2017/2018/2019 (<b>top 30%</b> highest-rating reviewer for NeurIPS 2018)<br>
	ICML 2018/2019/2020<br>
	IEEE ISIT 2019<br>
</p>
<p>
<b>Journal reviewer:</b><br> 
	Journal on Machine Learning Research<br>
	IEEE Trans. on Mobile Computing<br> 
	IEEE Trans. on Wireless Communications<br> 
	IEEE Trans. on Vehicular Technology<br> 
	Ad Hoc Networks<br>
</p>

---

## Graduate Courses at UT-Austin
<p>
<b>2016 Fall</b><br>
CS395T <a href="http://www.cs.utexas.edu/~ecprice/courses/sublinear/">Sublinear Algorithms</a> (Prof. Eric Price)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<i>Course project</i>: <b><a href="../files/RescaledJL_project.pdf">Rescaled JL Embedding</a></b> 
</p>
<p>
<b>2016 Spring</b><br>
EE381K-6 <a href="http://users.ece.utexas.edu/~hvikalo/ee381k6.html">Estimation Theory</a> (Prof. Haris Vikalo)<br>       
&nbsp;&nbsp;&nbsp;&nbsp;<i>Course project</i>: <b><a href="../files/EstTheory_project.pdf">A Survey of Fast Kernel Sketching Algorithms</a></b>   
</p>
<p>
<b>2015 Fall</b><br>
EE381V Advanced Probability in Learning, Inference, and Networks (Prof. Sanjay Shakkottai)<br>     
&nbsp;&nbsp;&nbsp;&nbsp;<i>Course project</i>: <b><a href="../files/AdvProb_project.pdf">Low-Rank Approximation of Matrix Product in One Pass</a></b><br>      
CS388G <a href="http://www.cs.utexas.edu/~vlr/courses/f15.388g/index.html">Algorithms: Techniques/Theory</a> (Prof. Vijaya Ramachandran)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<i>Course project</i>: <b><a href="../files/Algo_project.pdf">PTAS for the Euclidean Traveling Salesman Problem</a></b>
</p>
<p>
<b>2015 Summer (Online courses provided by edX)</b><br>
CS100.1x <a href="https://www.edx.org/course/introduction-big-data-apache-spark-uc-berkeleyx-cs100-1x">Introduction to Big Data with Apache Spark</a> (Prof. Anthony D. Joseph) &nbsp;&nbsp;&nbsp;&nbsp;<a href="../files/Certificate1001x.pdf"><i>Certificate</i></a><br>
CS190.1x <a href="https://www.edx.org/course/scalable-machine-learning-uc-berkeleyx-cs190-1x">Scalable Machine Learning</a> (Prof. Ameet Talwalkar) &nbsp;&nbsp;&nbsp;&nbsp;<a href="../files/Certificate1901x.pdf"><i>Certificate</i></a>
</p>
<p>
<b>2015 Spring</b><br>
EE381V Advanced Algorithms (Prof. Evdokia Nikolova)<br> 
&nbsp;&nbsp;&nbsp;&nbsp;<i>Course project</i>: <b><a href="../files/AdvAlgo_project.pdf">Signal Recovery from Permuted Observations</a></b><br>  
EE381K Information Theory (Prof. Alex Dimakis) 
</p>
<p>
<b>2014 Fall</b><br> 
EE380L <a href="http://hercules.ece.utexas.edu/courses/ee380l-f14/">Data Mining</a> (Prof. Joydeep Ghosh)<br>  
&nbsp;&nbsp;&nbsp;&nbsp;<i>Course project</i>: <b><a href="../files/DataMining_project.pdf">Ranking by Alternating SVM and Factorization Machine</a></b><br> 
EE381V Large-Scale Optimization (Prof. Sujay Sanghavi)<br> 
EE381J Probability and Stochastic Processes (Prof. Sanjay Shakkottai)
</p>
---

## Teaching Experiences
<p>
Teaching Assistant, EE381V (Machine Learning for Large Scale Data), UT-Austin, Spring 2016.  
</p>
<p>
Teaching Assistant, EE313 (Linear Systems and Signals), UT-Austin, Fall 2014. 
</p>
<p>
Teaching Assistant, VE489 (Computer Networks), <a href="http://umji.sjtu.edu.cn/">UM-SJTU Joint Institute</a>, Summer 2013.
</p>
<p>
Teaching Assistant, VP140 (Physics I), <a href="http://umji.sjtu.edu.cn/">UM-SJTU Joint Institute</a>, Summer 2009. 
</p>
---
<p>
Last update: Sept 27, 2020

</p>
